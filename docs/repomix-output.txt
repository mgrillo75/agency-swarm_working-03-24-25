This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-06T04:12:25.661Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
advanced-usage/agencies.md
advanced-usage/agents.md
advanced-usage/azure-openai.md
advanced-usage/communication_flows.md
advanced-usage/open-source-models.md
advanced-usage/tools.md
api.md
contributing.md
deployment.md
examples.md
index.md
quick_start.md

================================================================
Repository Files
================================================================

================
File: advanced-usage/agencies.md
================
# Agencies

An `Agency` is a collection of Agents that can communicate with one another.

### Benefits of using an Agency

Here are the primary benefits of using an Agency, instead of an individual agent:

1. **Fewer hallucinations**: When agents are part of an agency, they can supervise one another and recover from mistakes or unexpected circumstances.
2. **More complex tasks**: The more agents you add, the longer the sequence of actions they can perform before returning the result back to the user.
3. **Scalability**: As the complexity of your integration increases, you can keep adding more and more agents.

    !!! tip
        It is recommended to start with as few agents as possible, fine-tune them until they are working as expected, and only then add new agents to the agency. If you add too many agents at first, it will be difficult to debug and understand what is going on.

## Communication Flows

Unlike all other frameworks, communication flows in Agency Swarm are **not hierarchical** or **sequential**. Instead, they are **uniform**. You can define them however you want. But keep in mind that they are established from left to right inside the `agency_chart`. So, in the example below, the CEO can initiate communication and send tasks to the Developer and the Virtual Assistant, and they can respond back to him in the same thread, but the Developer or the VA cannot initiate a conversation and assign tasks to the CEO. You can add as many levels of communication as you want.

```python
from agency_swarm import Agency

agency = Agency([
    ceo, dev  # CEO and Developer will be the entry point for communication with the user
    [ceo, dev],  # CEO can initiate communication with Developer
    [ceo, va],   # CEO can initiate communication with Virtual Assistant
    [dev, va]    # Developer can initiate communication with Virtual Assistant
])
```

All agents added inside the top-level list of `agency_chart` without being part of a second list, can talk to the user.

## Streaming Responses

To stream the conversation between agents, you can use the `get_completion_stream` method with your event handler like below. The process is extremely similar to the one in the [official documentation](https://platform.openai.com/docs/assistants/overview/step-4-create-a-run?context=with-streaming).

The only difference is that you must extend the `AgencyEventHandler` class, which has 2 additional properties: `agent_name` and `recipient_agent_name`, to get the names of the agents communicating with each other. (See the `on_text_created` below.)


```python
from typing_extensions import override
from agency_swarm import AgencyEventHandler

class EventHandler(AgencyEventHandler):
    @override
    def on_text_created(self, text) -> None:
        # get the name of the agent that is sending the message
        print(f"\n{self.recipient_agent_name} @ {self.agent_name}  > ", end="", flush=True)

    @override
    def on_text_delta(self, delta, snapshot):
        print(delta.value, end="", flush=True)

    def on_tool_call_created(self, tool_call):
        print(f"\n{self.recipient_agent_name} > {tool_call.type}\n", flush=True)

    def on_tool_call_delta(self, delta, snapshot):
        if delta.type == 'code_interpreter':
            if delta.code_interpreter.input:
                print(delta.code_interpreter.input, end="", flush=True)
            if delta.code_interpreter.outputs:
                print(f"\n\noutput >", flush=True)
                for output in delta.code_interpreter.outputs:
                    if output.type == "logs":
                        print(f"\n{output.logs}", flush=True)

    @classmethod
    def on_all_streams_end(cls):
        print("\n\nAll streams have ended.") # Conversation is over and message is returned to the user.

response = agency.get_completion_stream("I want you to build me a website", event_handler=EventHandler)
```

Also, there is an additional class method `on_all_streams_end` which is called when all streams have ended. This method is needed because, unlike in the official documentation, your event handler will be called multiple times and probably by even multiple agents.

## Async Mode

When it comes to asynchronous execution, there are 2 modes you can use at the moment: `threading`, `tools_threading`.

### Agents - Threading

If you would like to use asynchronous communication between agents, you can specify a `async_mode` parameter to `threading`. This is useful when you don't want to wait for a response from an agent. For example, if it takes it long to write it.

```python
agency = Agency([ceo], async_mode='threading')
```

With this mode, the response from the `SendMessage` tool will be returned instantly as a system notification with a status update. The recipient agent will then continue to execute the task in the background. The caller agent can check the status (if task is in progress) or the response (if the task is completed) with the `GetResponse` tool.

### Tools - Threading

If you would like to use asynchronous execution for tools, you can specify a `async_mode` parameter to `tools_threading`. With this mode on, all tools will be executed concurrently in separate threads, which can significantly speed up the work flow of I/O bound tasks.

```python
agency = Agency([ceo], async_mode='tools_threading')
```


### Shared Files

You can add shared files for all agents in the agency by specifying a folder path in a `shared_files` parameter. This is useful for sharing common resources that all agents need to access.

```python
agency = Agency([ceo], shared_files='shared_files')
```

### Settings Path

If you would like to use a different file path for the settings, other than default `settings.json`, you can specify a `settings_path` parameter. All your agent states will then be saved and loaded from this file. If this file does not exist, it will be created, along with new Assistants on your OpenAI account.

```python
agency = Agency([ceo], settings_path='my_settings.json')
```

### Temperature and Max Token Controls

You can also specify parameters like `temperature`, `top_p`, `max_completion_tokens`,  `max_prompt_tokens` and `truncation_strategy`, parameters for the entire agency. These parameters will be used as default values for all agents in the agency, however, you can still override them for individual agents by specifying them in the agent's constructor.

```python
agency = Agency([ceo], temperature=0.3, max_prompt_tokens=25000)
```

## Running the Agency

When it comes to running the agency, you have 3 options:

1. **Run it inside a Gradio interface**: The most convenient way to get started.
2. **Get completion from the agency**: For backend or custom integrations.
3. **Run it from your terminal**: Best for quick debugging and testing.

### Running the Agency inside a Gradio Interface

```python
agency.demo_gradio(height=700)
```

### Get completion from the agency

```python
response = agency.get_completion("I want you to build me a website",
                                 additional_instructions="This is an additional instruction for the task.",
                                 tool_choice={"type": "function", "function": {"name": "SendMessage"}},
                                 attachments=[],
                                 recipient_agent=dev,
                                 )
print(response)
```

Params like `additional_instructions`, `tool_choice`, and `attachments` are optional. You can also specify the `recipient_agent` parameter to send the message to a specific agent.

### Running the Agency from your terminal

```bash
agency.run_demo()
```

To talk to one of the top-level agents when running the agency from your terminal, you can use **mentions feature**, similar to how you would use it inside ChatGPT. Simply mention the agent name in the message like `@Developer I want you to build me a website`. The message will then be sent to the Developer agent, instead of the CEO. You can also use tab to autocomplete the agent name after the `@` symbol.

## Deleting the Agency

If you would like to delete the agency and all its agents with all associated files and vector stores, you can use the `delete` method.

```python
agency.delete()
```

================
File: advanced-usage/agents.md
================
# Agents

Agents are essentially wrappers for [Assistants in OpenAI Assistants API](https://platform.openai.com/docs/assistants/how-it-works/creating-assistants). The `Agent` class contains a lot of convenience methods to help you manage the state of your assistant, upload files, attach tools, and more.


## Advanced Parameters

All parameters inside the Agent class, primarily follow the same structure as OpenAI's Assistants API. However, there are a few additional parameters that you can use to customize your agent.

### Parallel Tool Calls

You can specify weather to run tools in parallel or sequentially by setting the `parallel_tool_calls` parameter. By default, this parameter is set to `True`.

```python
from agency_swarm import Agent

agent = Agent(name='MyAgent', parallel_tool_calls=False)
```

Now, the agent will run all tools sequentially.

### File Search Configuration

You can also specify the file search configuration for the agent, as described in the [OpenAI documentation](https://platform.openai.com/docs/api-reference/assistants/createAssistant#assistants-createassistant-tools). Right now, only `max_num_results` is supported.

```python
from agency_swarm import Agent

agent = Agent(name='MyAgent', file_search={'max_num_results': 25}) # must be between 1 and 50
```

### Schemas Folder

You can specify the folder where the agent will look for OpenAPI schemas to convert into tools. Additionally, you can add `api_params` and `api_headers` to the schema to pass additional parameters and headers to the API call.

```python
from agency_swarm import Agent

agent = Agent(name='MyAgent',
              schemas_folder='schemas',
              api_params={'my_schema.json': {'param1': 'value1'}},
              api_headers={'my_schema.json': {'Authorization': 'Bearer token'}}
            )
```

!!! note
    Schemas folder automatically converts any OpenAPI schemas into BaseTools. This means that your agents will type check all the API parameters **before** calling the API, which significantly reduces any chances of errors.


### Fine Tuned models

You can use any previously fine-tuned model by specifying the `model` parameter in the agent.

```python
from agency_swarm import Agent

agent = Agent(name='MyAgent', model='gpt-3.5-turbo-model-name')
```

### Response Validator

You can also provide a response validator function to validate the response before sending it to the user or another agent. This function should raise an error if the response is invalid.

```python

from agency_swarm import Agent

class MyAgent(Agent):
    def response_validator(self, message: str) -> str:
        """This function is used to validate the response before sending it to the user or another agent."""
        if "bad word" in message:
            raise ValueError("Please don't use bad words.")

        return message
```

### Few-Shot Examples

You can now also provide **few-shot** examples for each agent. These examples help the agent to understand how to respond. The format for examples follows [message object format on OpenAI](https://platform.openai.com/docs/api-reference/messages/createMessage):

```python
examples=[
    {
        "role": "user",
        "content": "Hi!",
        "attachments": [],
        "metadata": {},
    },
    {
        "role": "assistant",
        "content": "Hi! I am the CEO. I am here to help you with your tasks. Please tell me what you need help with.",
        "attachments": [],
        "metadata": {},
    }
]

agent.examples = examples
```

or you can also provide them when initializing the agent in init method:

```python
agent = Agent(examples=examples)
```

## Creating Agents

When it comes to creating your agent, you have 3 options:

1. **Define the agent directly in the code.**
2. **Create agent template locally using CLI.**
3. **Import from existing agents.**

### Defining the agent directly in the code

To define your agent in the code, you can simply instantiate the `Agent` class and pass the required parameters.

```python
from agency_swarm import Agent

agent = Agent(name="My Agent",
              description="This is a description of my agent.",
              instructions="These are the instructions for my agent.",
              tools=[ToolClass1, ToolClass2],
              temperature=0.3,
              max_prompt_tokens=25000
            )
```

### Create agent template locally using CLI

This CLI command simplifies the process of creating a structured environment for each agent.

#### **Command Syntax:**

```bash
agency-swarm create-agent-template --name "AgentName" --description "Agent Description" [--path "/path/to/directory"] [--use_txt]
```

#### Folder Structure

When you run the `create-agent-template` command, it creates the following folder structure for your agent:

```
/your-specified-path/
â”‚
â”œâ”€â”€ agency_manifesto.md or .txt # Agency's guiding principles (created if not exists)
â””â”€â”€ AgentName/                  # Directory for the specific agent
    â”œâ”€â”€ files/                  # Directory for files that will be uploaded to openai
    â”œâ”€â”€ schemas/                # Directory for OpenAPI schemas to be converted into tools
    â”œâ”€â”€ tools/                  # Directory for tools to be imported by default.
    â”œâ”€â”€ AgentName.py            # The main agent class file
    â”œâ”€â”€ __init__.py             # Initializes the agent folder as a Python package
    â””â”€â”€ instructions.md or .txt # Instruction document for the agent

```

- `files`: This folder is used to store files that will be uploaded to OpenAI. You can use any of the [acceptable file formats](https://platform.openai.com/docs/assistants/tools/supported-files). After file is uploaded, an id will be attached to the file name to avoid re-uploading the same file twice.
- `schemas`: This folder is used to store OpenAPI schemas that will be converted into tools automatically. All you have to do is put the schema in this folder, and specify it when initializing your agent.
- `tools`: This folder is used to store tools in the form of Python files. Each file must have the same name as the tool class for it to be imported by default. For example, `ExampleTool.py` must contain a class called `ExampleTool`.

#### Agent Template

The `AgentName.py` file will contain the following code:

```python
from agency_swarm.agents import Agent

class AgentName(Agent):
    def __init__(self):
        super().__init__(
            name="agent_name",
            description="agent_description",
            instructions="./instructions.md",
            files_folder="./files",
            schemas_folder="./schemas",
            tools_folder="./tools",
            temperature=0.3,
            max_prompt_tokens=25000,
            examples=[]
        )

    def response_validator(self, message: str) -> str:
        """This function is used to validate the response before sending it to the user or another agent."""
        if "bad word" in message:
            raise ValueError("Please don't use bad words.")

        return message
```

To initialize the agent, you can simply import the agent and instantiate it:

```python
from AgentName import AgentName

agent = AgentName()
```

### Importing existing agents

For the most complex and requested use cases, we will be creating premade agents that you can import and reuse in your own projects. To import an existing agent, you can run the following CLI command:

```bash
agency-swarm import-agent --name "AgentName" --destination "/path/to/directory"
```

This will copy all your agent source files locally. You can then import the agent as shown above. To check available agents, simply run this command without any arguments.

================
File: advanced-usage/azure-openai.md
================
# Azure OpenAI

Many organizations are concerned about data privacy and sharing their data with OpenAI. However, using Azure ensures that your data is processed in a secure environment, allowing you to utilize the OpenAI API without even sharing data with OpenAI itself.

## Prerequisites

Before you begin, ensure that you have the following:

- An Azure account with an active subscription. [Create an account here](https://azure.microsoft.com/en-us/free/).
- Approved access to the OpenAI Service on Azure.
- An Azure OpenAI resource created in [one of the available regions](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#assistants-preview) and a model deployed to it.
- Enpoint URL and API key for the OpenAI resource.

## Using Azure OpenAI

To use Azure OpenAI, you need to change OpenAI client with AzureOpenAI client. Here is an example of how you can do it in agency swarm:

```python
from openai import AzureOpenAI
from agency_swarm import set_openai_client

client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_KEY"),
    api_version="2024-02-15-preview",
    azure_endpoint=os.getenv("AZURE_ENDPOINT"),
    timeout=5,
    max_retries=5,
)

set_openai_client(client)
```

Then, you also have to replace `model` parameter inside each agent with your model deployment name from Azure. Here is an example of how you can do it:

```python
ceo = Agent(name="ceo", description="I am the CEO", model='azure-model-deployment-name')
```

Then, you can run your agency as usual:

```python
agency = Agency([ceo])
agency.run_demo()
```

!!! warning "Retrieval is not supported yet"
    Currently, Azure OpenAI does not support the `Retrieval` tool. You can only use `CodeInterpreter` or custom tools made with the `BaseTool` class.

## Example Notebook

You can find an example notebook for using Azure OpenAI in the [notebooks folder](https://github.com/VRSEN/agency-swarm/blob/main/notebooks/azure.ipynb).

================
File: advanced-usage/communication_flows.md
================
# Advanced Communication Flows

Multi-agent communication is the core functionality of any Multi-Agent System. Unlike in all other frameworks, Agency Swarm not only allows you to define communication flows in any way you want (uniform communication flows), but to also configure the underlying logic for this feature. This means that you can create entirely new types of communication, or adjust it to your own needs. Below you will find a guide on how to do all this, along with some common examples.

## Pre-Made SendMessage Classes

Agency Swarm contains multiple commonly requested classes for communication flows. Currently, the following classes are available:

| Class Name                  | Description                                                                                                                                                                                                                               | When to Use                                                                                                    | Code Link                                                                                                            |
| --------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------- |
| `SendMessage` (default)     | This is the default class for sending messages to other agents. It uses synchronous communication with basic COT (Chain of Thought) prompting and allows agents to relay files and modify system instructions for each other.             | Suitable for most use cases. Balances speed and functionality.                                                 | [link](https://github.com/VRSEN/agency-swarm/blob/main/agency_swarm/tools/send_message/SendMessage.py)               |
| `SendMessageQuick`          | A variant of the SendMessage class without Chain of Thought prompting, files, and additional instructions. It allows for faster communication without the overhead of COT.                                                                | Use for simpler use cases or when you want to save tokens and increase speed.                                  | [link](https://github.com/VRSEN/agency-swarm/blob/main/agency_swarm/tools/send_message/SendMessageQuick.py)          |
| `SendMessageAsyncThreading` | Similar to `SendMessage` but with `async_mode='threading'`. Each agent will execute asynchronously in a separate thread. In the meantime, the caller agent can continue the conversation with the user and check the results later.       | Use for asynchronous applications or when sub-agents take singificant amounts of time to complete their tasks. | [link](https://github.com/VRSEN/agency-swarm/blob/main/agency_swarm/tools/send_message/SendMessageAsyncThreading.py) |
| `SendMessageSwarm`          | Instead of sending a message to another agent, it replaces the caller agent with the recipient agent, similar to [OpenAI's Swarm](https://github.com/openai/swarm). The recipient agent will then have access to the entire conversation. | When you need more granular control. It is not able to handle complex multi-step, multi-agent tasks.           | [link](https://github.com/VRSEN/agency-swarm/blob/main/agency_swarm/tools/send_message/SendMessageSwarm.py)          |

**To use any of the pre-made `SendMessage` classes**, simply put it in the `send_message_tool_class` parameter when initializing the `Agency` class:

```python
from agency_swarm.tools.send_message import SendMessageQuick

agency = Agency(
    ...
    send_message_tool_class=SendMessageQuick
)
```

That's it! Now, your agents will use your own custom `SendMessageQuick` class for communication.

## Creating Your Own Unique Communication Flows

To create you own communication flow, you will first need to extend the `SendMessageBase` class. This class extends the `BaseTool` class, like any other tools in Agency Swarm, and contains the most basic parameters required for communication, such as the `recipient_agent`.

### Default `SendMessage` Class

By defualt, Agency Swarm uses the following tool for communication:

```python
from typing import Optional, List
from pydantic import Field, field_validator, model_validator
from .SendMessageBase import SendMessageBase

class SendMessage(SendMessageBase):
    """Use this tool to facilitate direct, synchronous communication between specialized agents within your agency. When you send a message using this tool, you receive a response exclusively from the designated recipient agent. To continue the dialogue, invoke this tool again with the desired recipient agent and your follow-up message. Remember, communication here is synchronous; the recipient agent won't perform any tasks post-response. You are responsible for relaying the recipient agent's responses back to the user, as the user does not have direct access to these replies. Keep engaging with the tool for continuous interaction until the task is fully resolved. Do not send more than 1 message to the same recipient agent at the same time."""
    my_primary_instructions: str = Field(
        ...,
        description=(
            "Please repeat your primary instructions step-by-step, including both completed "
            "and the following next steps that you need to perform. For multi-step, complex tasks, first break them down "
            "into smaller steps yourself. Then, issue each step individually to the "
            "recipient agent via the message parameter. Each identified step should be "
            "sent in a separate message. Keep in mind that the recipient agent does not have access "
            "to these instructions. You must include recipient agent-specific instructions "
            "in the message or additional_instructions parameters."
        )
    )
    message: str = Field(
        ...,
        description="Specify the task required for the recipient agent to complete. Focus on clarifying what the task entails, rather than providing exact instructions. Make sure to inlcude all the relevant information needed to complete the task."
    )
    message_files: Optional[List[str]] = Field(
        default=None,
        description="A list of file IDs to be sent as attachments to this message. Only use this if you have the file ID that starts with 'file-'.",
        examples=["file-1234", "file-5678"]
    )
    additional_instructions: Optional[str] = Field(
        default=None,
        description="Additional context or instructions from the conversation needed by the recipient agent to complete the task."
    )

    @model_validator(mode='after')
    def validate_files(self):
        # prevent hallucinations with agents sending file IDs into incorrect fields
        if "file-" in self.message or (self.additional_instructions and "file-" in self.additional_instructions):
            if not self.message_files:
                raise ValueError("You must include file IDs in message_files parameter.")
        return self


    def run(self):
        return self._get_completion(message=self.message,
                                    message_files=self.message_files,
                                    additional_instructions=self.additional_instructions)
```

Let's break down the code.

In general, all `SendMessage` tools have the following components:

1. **The Docstring**: This is used to generate a description of the tool for the agent. This part should clearly describe how your multi-agent communication works, along with some additional guidelines on how to use it.
2. **Parameters**: Parameters like `message`, `message_files`, `additional_instructions` are used to provide the recipient agent with the necessary information.
3. **The `run` method**: This is where the communication logic is implemented. Most of the time, you just need to map your parameters to `self._get_completion()` the same way you would call it in the `agency.get_completion()` method.

When creating your own `SendMessage` tools, you can use the above components as a template.

### Common Use Cases

In the following sections, we'll look at some common use cases for extending the `SendMessageBase` tool and how to implement them, so you can learn how to create your own SendMessage tools and use them in your own applications.

#### 1. Adjusting parameters and descriptions

The most basic use case is if you want to use your own parameter descriptions, such as if you want to change the docstring or the description of the `message` parameter. This can help you better customize how the agents communicate with each other and what information they relay.

Let's say that instead of sending messages, I want my agents to send tasks to each other. In this case, I can change the docstring and the `message` parameter to a `task` parameter to better fit the nature of my application.

```python
from pydantic import Field
from agency_swarm.tools.send_message import SendMessageBase

class SendMessageTask(SendMessageBase):
    """Use this tool to send tasks to other agents within your agency."""
    chain_of_thought: str = Field(
        ...,
        description="Please think step-by-step about how to solve your current task, provided by the user. Then, break down this task into smaller steps and issue each step individually to the recipient agent via the task parameter."
    )
    task: str = Field(
        ...,
        description="Specify the task required for the recipient agent to complete. Focus on clarifying what the task entails, rather than providing exact instructions. Make sure to inlcude all the relevant information needed to complete the task."
    )

    def run(self):
        return self._get_completion(message=self.task)
```

To remove the chain of thought, you can simply remove the `chain_of_thought` parameter.

#### 2. Adding custom validation logic

Now, let's say that I need to ensure that my message is sent to the correct recepient agent. (This is a very common hallucination in production.) In this case, I can add custom validator to the `recipient` parameter, which is defined in the `SendMessageBase` class. Since I don't want to change any other parameters or descriptions, I can inherit the default `SendMessage` class and only add this new validation logic.

```python
from agency_swarm.tools.send_message import SendMessage
from pydantic import model_validator

class SendMessageValidation(SendMessage):
    @model_validator(mode='after')
    def validate_recipient(self):
        if "customer support" not in self.message.lower() and self.recipient == "CustomerSupportAgent":
            raise ValueError("Messages not related to customer support cannot be sent to the customer support agent.")
        return self
```

You can, of course, also use GPT for this:

```python
from agency_swarm.tools.send_message import SendMessage
from agency_swarm.util.validators import llm_validator
from pydantic import model_validator

class SendMessageLLMValidation(SendMessage):
    @model_validator(mode='after')
    def validate_recipient(self):
        if self.recipient == "CustomerSupportAgent":
            llm_validator(
                statement="The message is related to customer support."
            )(self.message)
        return self
```

In this example, the `llm_validator` will throw an error if the message is not related to customer support. The caller agent will then have to fix the recipient or the message and send it again! This is extremely useful when you have a lot of agents.

#### 3. Summurizing previous conversations with other agents and adding to context

Sometimes, when using default `SendMessage`, the agents might not relay all the neceessary details to the recipient agent. Especially, when the previous conversation is too long. In this case, you can summarize the previous conversation with GPT and add it to the context, instead of the additional instructions. I will extend the `SendMessageQuick` class, which already contains the `message` parameter, as I don't need chain of thought or files in this case.

```python
from agency_swarm.tools.send_message import SendMessageQuick
from agency_swarm.util.oai import get_openai_client

class SendMessageSummary(SendMessageQuick):
    def run(self):
        client = get_openai_client()
        thread = self._get_main_thread() # get the main thread (conversation with the user)

        # get the previous messages
        previous_messages = thread.get_messages()
        previous_messages_str = "\n".join([f"{m.role}: {m.content[0].text.value}" for m in previous_messages])

        # summarize the previous conversation
        summary = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a world-class summarizer. Please summarize the following conversation in a few sentences:"},
                {"role": "user", "content": previous_messages_str}
            ]
        )

        # send the message with the summary
        return self._get_completion(message=self.message, additional_instructions=f"\n\nPrevious conversation summary: '{summary.choices[0].message.content}'")
```

With this example, you can add your own custom logic to the `run` method. It does not have to be a summary; you can also use it to add any other information to the context. For example, you can even query a vector database or use an external API.

#### 4. Running each agent in a separate API call

If you are a PRO, and you have managed to deploy each agent in a separate API endpoint, instead of using `_get_completion()`, you can call your own API and let the agents communicate with each other over the internet.

```python
import requests
from agency_swarm.tools.send_message import SendMessage

class SendMessageAPI(SendMessage):
    def run(self):
        response = requests.post(
            "https://your-api-endpoint.com/send-message",
            json={"message": self.message, "recipient": self.recipient}
        )
        return response.json()["message"]
```

This is very powerful, as you can even allow your agents to colloborate with agents outside your system. More on this is coming soon!

!!! tip "Contributing"

    If you have any ideas for new communication flows, please either adjust this page in docs, or add your new send message tool in the `agency_swarm/tools/send_message` folder and open a PR!

**After implementing your own `SendMessage` tool**, simply pass it into the `send_message_tool_class` parameter when initializing the `Agency` class:

```python
agency = Agency(
    ...
    send_message_tool_class=SendMessageAPI
)
```

That's it! Now, your agents will use your own custom `SendMessageAPI` class for communication!

## Conclusion

Agency Swarm has been designed to give you, the developer, full control over your systems. It is the only framework that does not hard-code any prompts, parameters, or even worse, agents for you. With this new feature, the last part of the system that you couldn't fully customize to your own needs is now gone!

So, I want to encourage you to keep experimenting and designing your own unique communication flows. While the examples above should serve as a good starting point, they do not even merely scratch the surface of what's possible here! I am looking forward to seeing what you will create. Please share it in our [Discord server](https://discord.gg/7HcABDpFPG) so we can all learn from each other.

================
File: advanced-usage/open-source-models.md
================
# Open Source Models

While OpenAI is generally recommended, there are situations where you might prefer open-source models. The following projects offer alternatives by mimicking the Assistants API:

### âœ… Tested Projects
- [Astra Assistants API](https://github.com/datastax/astra-assistants-api) - The best and the easiest option for running Open Source models. Supports Assistants API V2. See example [notebook](https://github.com/VRSEN/agency-swarm/blob/main/notebooks/os_models_with_astra_assistants_api.ipynb).
- [Open Assistant API](https://github.com/MLT-OSS/open-assistant-api) - Fully local, stable and tested, but only supports Assistants V1. See example [here](https://github.com/VRSEN/agency-swarm-lab/tree/main/OpenSourceSwarm)

### ðŸ”œ Other Projects
- [OpenOpenAI](https://github.com/transitive-bullshit/OpenOpenAI) - Unverified.
- [LiteLLM](https://github.com/BerriAI/litellm/issues/2842) - Assistants API Proxy in development.

## Astra Assistants API

To use agency-swarm with Astra Assistants API, follow these steps:

**1. Create an account on [Astra Assistants API](https://astra.datastax.com/signup) and obtain an API key.**

![Astra Assistants API Example](https://firebasestorage.googleapis.com/v0/b/vrsen-ai/o/public%2Fgithub%2FScreenshot%202024-07-01%20at%208.19.00%E2%80%AFAM.png?alt=media&token=b4f1a7ad-3b77-40fa-a5da-866a4f1410bd)

**2. Add Astra DB Token to your .env file:**
    Copy token from the file that starts with "AstraCS:" and paste it into your .env file.

```env
ASTRA_DB_APPLICATION_TOKEN=AstraCS:dsfkgn...
```

**3. Add other model provider API keys to .env as well:**

```env
PERPLEXITYAI_API_KEY=your_perplexityai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
TOGETHER_API_KEY=your_together_api_key
GROQ_API_KEY=your_groq_api_key
```

**4. Install the Astra Assistants API and gradio:**

```bash
pip install astra-assistants-api gradio
```

**5. Patch the OpenAI client:**

```python
from openai import OpenAI
from astra_assistants import patch
from agency_swarm import set_openai_client
from dotenv import load_dotenv

load_dotenv()

client = patch(OpenAI())

set_openai_client(client)
```

**6. Create an agent:**
    Create an agent and replace the model parameter with the name of the model you want to use. With Astra Assistants you can upload files like usual using `files_folder`.

```python
from agency_swarm import Agent

ceo = Agent(name="ceo",
            description="I am the CEO",
            model='ollama/llama3',
            # model = 'perplexity/llama-3-8b-instruct'
            # model = 'anthropic/claude-3-5-sonnet-20240620'
            # model = 'groq/mixtral-8x7b-32768'
            # model="gpt-4o",
            files_folder="path/to/your/files"
            )
```

**7. Create an agency:**

You can add more agents as needed, just make sure all manager agents support function calling.

```python
from agency_swarm import Agency

agency = Agency([ceo])
```

**8. Start gradio:**

To utilize your agency in gradio, apply a specific non-streaming `demo_gradio` method from the [agency-swarm-lab](https://github.com/VRSEN/agency-swarm-lab/blob/main/OpenSourceSwarm/demo_gradio.py) repository:

```python
from agency_swarm import Agency
from .demo_gradio import demo_gradio

agency = Agency([ceo])

demo_gradio(agency)
```

**For a complete example, see the [notebook](https://github.com/VRSEN/agency-swarm/blob/main/notebooks/os_models_with_astra_assistants_api.ipynb).**

## General Instructions

To use agency-swarm with any other projects that mimic the Assistants API, generally, you need to follow these steps:

**1. Install the previous version of agency-swarm as most projects are not yet compatible with streaming and Assistants V2:**

```bash
pip install agency-swarm==0.1.7
```

**2. Switch out the OpenAI client:**

```python
import openai
from agency_swarm import set_openai_client

client = openai.OpenAI(api_key="whatever", base_url="http://127.0.0.1:8000/")

set_openai_client(client)
```

**3. Set the model parameter:**

```python
from agency_swarm import Agent

ceo = Agent(name="ceo", description="I am the CEO", model='ollama/llama3')
```

**4. Start Gradio:**

To utilize your agency in gradio, apply a specific non-streaming `demo_gradio` method from the [agency-swarm-lab](https://github.com/VRSEN/agency-swarm-lab/blob/main/OpenSourceSwarm/demo_gradio.py) repository:

```python
from agency_swarm import Agency
from .demo_gradio import demo_gradio

agency = Agency([ceo])

demo_gradio(agency)
```

**5. For backend integrations, simply use:**

```python
agency.get_completion("I am the CEO")
```

## Limitations

- **Function calling is not supported by most open-source models**: This limitation prevents the agent from communicating with other agents in the agency. So, it must be positioned at the end of the agency chart and cannot utilize any tools.
- **RAG is typically limited**: Most open-source assistants API implementations have restricted Retrieval-Augmented Generation capabilities. It is recommended to develop a custom tool with your own vector database.
- **CodeInterpreter is not supported**: The Code Interpreter feature is still under development for all open-source assistants API implementations.

## Future Plans

Updates will be provided as new open-source assistant API implementations stabilize.

If you successfully integrate other projects with agency-swarm, please share your experience through an issue or pull request.

================
File: advanced-usage/tools.md
================
# Advanced Tools

All tools in Agency Swarm are created using [Instructor](https://github.com/jxnl/instructor).

The only difference is that you must extend the `BaseTool` class and implement the `run` method with your logic inside. For many great examples on what you can create, checkout [Instructor Cookbook](https://jxnl.github.io/instructor/examples/).

---

## Example: Converting [Answering Questions with Validated Citations Example](https://jxnl.github.io/instructor/examples/exact_citations/) from Instructor

This is an example of how to convert an extremely useful tool for RAG applications from instructor. It allows your agents to not only answer questions based on context, but also to provide the exact citations for the answers. This way your users can be sure that the information is always accurate and reliable.


### Original Instructor library implementation


```python
from agency_swarm.tools import BaseTool, BaseModel
from pydantic import Field, model_validator, FieldValidationInfo
from typing import List
import re

class Fact(BaseModel):
    fact: str = Field(...)
    substring_quote: List[str] = Field(...)

    @model_validator(mode="after")
    def validate_sources(self, info: FieldValidationInfo) -> "Fact":
        text_chunks = info.context.get("text_chunk", None)
        spans = list(self.get_spans(text_chunks))
        self.substring_quote = [text_chunks[span[0] : span[1]] for span in spans]
        return self

    def get_spans(self, context):
        for quote in self.substring_quote:
            yield from self._get_span(quote, context)

    def _get_span(self, quote, context):
        for match in re.finditer(re.escape(quote), context):
            yield match.span()

class QuestionAnswer(BaseModel):
    question: str = Field(...)
    answer: List[Fact] = Field(...)

    @model_validator(mode="after")
    def validate_sources(self) -> "QuestionAnswer":
        self.answer = [fact for fact in self.answer if len(fact.substring_quote) > 0]
        return self
```

!!! note "Context Retrieval"
    In the original Instructor example, [the context is passed into the prompt beforehand](https://jxnl.github.io/instructor/examples/exact_citations/#the-ask_ai-function), which is typical for standard non-agent LLM applications. However, in the context of Agency Swarm, we must allow the agents to retrieve the context themselves.

### Agency Swarm Implementation

To allow your agents to retrieve the context themselves, we must split `QuestionAnswer` into two separate tools: `QueryDatabase` and `AnswerQuestion`. We must also retrieve context from `shared_state`, as the context is not passed into the prompt beforehand, and `FieldValidationInfo` is not available in the `validate_sources` method.

#### The `QueryDatabase` tool will:

1. Check if the context is already retrieved in `shared_state`. If it is, raise an error. (This means that the agent retrieved the context twice, without answering the question in between, which is most likely a hallucination.)
2. Retrieve the context and save it to the `shared_state`.
3. Return the context to the agent, so it can be used to answer the question.

```python
class QueryDatabase(BaseTool):
    """Use this tool to query a vector database to retrieve the relevant context for the question."""
    question: str = Field(..., description="The question to be answered")

    def run(self):
        # Check if context is already retrieved
        if self._shared_state.get("context", None) is not None:
            raise ValueError("Context already retrieved. Please proceed with the AnswerQuestion tool.")

        # Your code to retrieve the context here
        context = "This is a test context"

        # Then, save the context to the shared state
        self._shared_state.set("context", context)

        return f"Context retrieved: {context}.\n\n Please proceed with the AnswerQuestion tool."

```

!!! note "Shared State"
    `shared_state` is a state that is shared between all tools, across all agents. It allows you to control the execution flow, share data, and provide instructions to the agents based on certain conditions or actions performed by other agents.

#### The `AnswerQuestion` tool will:

1. Check if the context is already retrieved. If it is not, raise an error. (This means that the agent is trying to answer the question without retrieving the context first.)
2. Use the context from the `shared_state` to answer the question with a list of facts.
3. Remove the context from the `shared_state` after the question is answered. (This is done, so the next  question can be answered with a fresh context.)


```python
class AnswerQuestion(BaseTool):
    answer: str = Field(..., description="The answer to the question, based on context.")
    sources: List[Fact] = Field(..., description="The sources of the answer")

    def run(self):
        # Remove the context after question is answered
        self._shared_state.set("context", None)

        # additional logic here as needed, for example save the answer to a database

        return "Success. The question has been answered." # or return the answer, if needed

    @model_validator(mode="after")
    def validate_sources(self) -> "QuestionAnswer":
        # In "Agency Swarm", context is directly extracted from `shared_state`
        context = self._shared_state.get("context", None)  # Highlighting the change
        if context is None:
            # Additional check to ensure context is retrieved before proceeding
            raise ValueError("Please retrieve the context with the QueryDatabase tool first.")
        self.answer = [fact for fact in self.answer if len(fact.substring_quote) > 0]
        return self


```

#### The `Fact` tool

The `Fact` tool will stay primarily the same. The only difference is that we must extract the context from the `shared_state` inside the `validate_sources` method. The `run` method is not needed, as this tool only validates the input from the model.

```python
class Fact(BaseTool):
    fact: str = Field(...)
    substring_quote: List[str] = Field(...)

    def run(self):
        pass

    @model_validator(mode="after")
    def validate_sources(self) -> "Fact":
        context = self._shared_state.get("context", None)
        text_chunks = context.get("text_chunk", None)
        spans = list(self.get_spans(text_chunks))
        self.substring_quote = [text_chunks[span[0] : span[1]] for span in spans]
        return self

    # Methods `get_spans` and `_get_span` remain unchanged

```


### Conclusion

To implement tools with Instructor in Agency Swarm, generally, you must:

1. Extend the `BaseTool` class.
2. Add fields with types and clear descriptions, plus the tool description itself.
3. Implement the `run` method with your execution logic inside.
4. Add validators and checks based on various conditions.
5. Split tools into smaller tools to give your agents more control, as needed.


---


## ToolFactory Class

Tool factory is a class that allows you to create tools from different sources. You can create tools from Langchain, OpenAPI schemas. However, it is preferable to implement tools from scratch using Instructor, as it gives you a lot more control.

### Import from Langchain

!!! warning "Not recommended"
    This method is not recommended, as it does not provide the same level of type checking, error correction and tool descriptions as Instructor. However, it is still possible to use this method if you prefer.

    ```python
    from langchain.tools import YouTubeSearchTool
    from agency_swarm.tools import ToolFactory

    LangchainTool = ToolFactory.from_langchain_tool(YouTubeSearchTool)
    ```

    ```python
    from langchain.agents import load_tools

    tools = load_tools(
        ["arxiv", "human"],
    )

    tools = ToolFactory.from_langchain_tools(tools)
    ```

### Convert from OpenAPI schemas

```python
# using local file
with open("schemas/your_schema.json") as f:
    tools = ToolFactory.from_openapi_schema(
        f.read(),
    )

# using requests
tools = ToolFactory.from_openapi_schema(
    requests.get("https://api.example.com/openapi.json").json(),
)
```

!!! note
    Schemas folder automatically converts any OpenAPI schemas into BaseTools. This means that your agents will type check all the API parameters **before** calling the API, which significantly reduces any chances of errors.

---

## PRO Tips

1. Use enumerators or Literal types instead of strings to allow your agents to perform only certain actions or commands, instead of executing any arbitrary code. This makes your whole system a lot more reliable.

    ```python
    class RunCommand(BaseTool):
        command: Literal["start", "stop"] = Field(...)

       def run(self):
            if command == "start":
                subprocess.run(["start", "your_command"])
            elif command == "stop":
                subprocess.run(["stop", "your_command"])
            else:
                raise ValueError("Invalid command")
    ```


2. Provide additional instructions to the agents in the `run` method of the tool as function outputs. This allows you to control the execution flow, based on certain conditions.

    ```python
    class QueryDatabase(BaseTool):
        question: str = Field(...)

        def run(self):
            # query your database here
            context = query_database(self.question)

            if context is None:
                raise ValueError("No context found. Please propose to the user to change the topic.")
            else:
                self._shared_state.set("context", context)
                return "Context retrieved. Please proceed with explaining the answer."
    ```
3. Use `shared_state` to validate actions taken by other agents, before allowing them to proceed with the next action.

    ```python
    class Action2(BaseTool):
        input: str = Field(...)

        def run(self):
            if self._shared_state.get("action_1_result", None) is "failure":
                raise ValueError("Please proceed with the Action1 tool first.")
            else:
                return "Success. The action has been taken."
    ```
4. Consider `one_call_at_a_time` ToolConfig class attribute to prevent multiple instances of the same tool from running at the same time. This is useful when you want your agents to see the results of the previous action before proceeding with the next one.

    ```python
    class Action1(BaseTool):
        input: str = Field(...)

        class ToolConfig:
            one_call_at_a_time = True

        def run(self):
            # your code here
    ```
5. Enable [strict mode](https://openai.com/index/introducing-structured-outputs-in-the-api/) for extremely complex nested schemas or mission crictical tools.

    ```python
    class GetWeatherTool(BaseTool):
    """
    Determine weather in a specified location.
    """

    location: str = Field(..., description="The city and state e.g. San Francisco, CA")

    class ToolConfig:
      strict = True # setting strict to true

    def run(self):
        return f"The weather in {self.location} is 30 degrees."
    ```

================
File: api.md
================
# API Reference

::: agency_swarm.agents.agent

::: agency_swarm.agency.agency

::: agency_swarm.tools.ToolFactory

================
File: contributing.md
================
# Contributing to Agency Swarm

Each agent or tool you add to Agency Swarm will automatically be available for import by the Genesis Swarm, which will help us create an exponentially larger and smarter system.

This document provides guidelines for contributing new agents and tools to the framework.

!!! warning "Will be updated soon"
    The way we contribute agents and tools will be updated soon to load source files directly from the repository, rather than import them into the framework. This will allow you to have full control over all your agents and tools.

### Folder Structure for Tools
Tools should be added in the agency_swarm/tools/{category}/ directory like below.
Each tool should be in its specific category folder like coding, browsing, investing etc.

Your tool file should be named YourNewTool.py.
Tests should be added in agency_swarm/tests/test_tools.py.
Directory structure for a new tool:

```py
agency_swarm/tools/your-tool-category/
â”‚
â”œâ”€â”€ YourNewTool.py          # The main agent class file
â””â”€â”€ __init__.py             # Make sure to import your tool here
```
### Adding Tests For Your Tools
For each tool, please add the following test case in agency_swarm/tests/test_tools.py:
```py
    def test_my_tool_example(self):
        output = MyCustomTool(query='John Doe').run()
        self.assertFalse("error" in output.lower())
```
### Folder Structure for Agents

Agents should be placed in agency_swarm/agents/{category}/ directory.
Each agent should have its dedicated folder named AgentName like below.
Make sure to use CamelCase for the agent name and the folder.
```python
agency_swarm/agents/your-agent-category/AgentName/
â”‚
â”œâ”€â”€ agency_manifesto.md or .txt # Agency's guiding principles (created if not exists)
â””â”€â”€ AgentName/                  # Directory for the specific agent
    â”œâ”€â”€ files/                  # Directory for files that will be uploaded to openai (if any)
    â”œâ”€â”€ schemas/                # Directory for OpenAPI schemas to be converted into tools (if any)
    â”œâ”€â”€ AgentName.py            # The main agent class file
    â”œâ”€â”€ __init__.py             # Initializes the agent folder as a Python package
    â””â”€â”€ instructions.md         # Instruction document for the agent
```
### Creating an Agent

Follow the structure below in your AgentName.py as a guideline.
All tools (except schemas) should be imported in AgentName.py from the agency_swarm/tools/... folder.
```python
from agency_swarm import Agent
from agency_swarm.tools.example import ExampleTool

class AgentName(Agent):
    def __init__(self, **kwargs):
        # Initialize tools in kwargs if not present
        if 'tools' not in kwargs:
            kwargs['tools'] = []
        # Add required tools
        kwargs['tools'].extend([ExampleTool])

        # Set instructions
        kwargs['instructions'] = "./instructions.md"

        # Add more kwargs as needed

        # Initialize the parent class
        super().__init__(**kwargs)
```


Thank you for contributing to Agency Swarm! Your efforts help us build a more robust and versatile framework.

================
File: deployment.md
================
# Deployment to Production

To deploy your Agency on a production server, typically, you need to do the following:

1. **Load Agents and Threads dynamically**: Depending on your use case, you may want to load different agents and threads, based on current user/chat/session.
2. **Deploy each agent as a separate microservice (optional)**: This is useful when you want to scale each agent independently.


## Loading Agents and Threads dynamically

To load agents and threads dynamically, based on specific conditions, you will need to implement `threads_callbacks` and `settings_callbacks` in your agency.

### Settings Callbacks

Settings is a list of dictionaries that contains states of all the agents within your agency. If any change is detected after you initialize it, settings will be updated, and new settings will be saved to a file specified by `settings_path`. `settings_callbacks` will be executed every time these settings are loaded or saved.

Here is an example of how you can use them:


```python
def load_settings(user_id):
    # your code to load settings from DB here
    settings = load_settings_from_db(user_id)
    return settings

def save_settings(new_settings: List[Dict]):
    # your code to save new_settings to DB here
    save_settings_to_db(new_settings)
```

### Threads Callbacks

Threads is a dictionary that contains all threads between your agents. Loading them from the database, allows your agents to continue their conversations where they left off, even if you are using stateless backend. `threads_callbacks` callbacks work in a same way as `settings_callbacks`, except they are kept in memory, instead of being saved to a file:

```python
def load_threads(chat_id):
    # your code to load threads from DB here
    threads = load_threads_from_db(chat_id)
    return threads

def save_threads(new_threads: Dict):
    # your code to save new_threads to DB here
    save_threads_to_db(new_threads)
```

!!! note
    Make sure you load and return settings and threads in the exact same format as they are saved.

### Example

Below is an example of how you initialize an agency with these callbacks. You will typically need to get some info like `user_id` or `chat_id` beforehand, and pass them into these callbacks, depending on your use case or business logic:

```python
agency = Agency([ceo],
                threads_callbacks={
                    'load': lambda: load_threads(chat_id),
                    'save': lambda new_threads: save_threads(new_threads)
                },
                settings_callbacks={
                    'load': lambda: load_settings(user_id),
                    'save': lambda new_settings: save_settings(new_settings)
                },
                settings_path='my_settings.json'
)
```

## Deploy each agent as a separate microservice

... coming soon ...

================
File: examples.md
================
# Examples

The best new examples and tutorials will be posted on my [YouTube Channel](https://youtube.com/@vrsen?si=GBk3V8ar6Dgemy0B).

## Agency Examples

Examples of Agencies can be found in the [agency-swarm-lab](https://github.com/VRSEN/agency-swarm-lab) repository:

- [WebDevCrafters](https://github.com/VRSEN/agency-swarm-lab/tree/main/WebDevCrafters) - Web Development Agency that builds responsive web applications using Next.js, React, and MUI.
- [CodeGuardiansAgency](https://github.com/VRSEN/agency-swarm-lab/tree/main/CodeGuardiansAgency) - Agency that runs only on the backend using github actions and submits code reviews on pull requests, according to your SOPs.


## Videos with Notebooks

- [Browsing Agent for QA Testing Agency](https://youtu.be/Yidy_ePo7pE?si=WMuWpb9_DVckIkP6) - This video shows how to use BrowsingAgent with GPT-4 vision inside a QA testing agency. It can also break captcha, as shown in [this video](https://youtu.be/qBs_50SzyBQ?si=w7e3GOhEztG8qDPE). The notebook is available [here](https://github.com/VRSEN/agency-swarm/blob/main/notebooks/web_browser_agent.ipynb).
- [Genesis Agency](https://youtu.be/qXxO7SvbGs8?si=uosmTSzzz6id_lLl) - This agency creates your agents for you. The notebook is available [here](https://github.com/VRSEN/agency-swarm/blob/main/notebooks/genesis_agency.ipynb).

### ... more coming soon

================
File: index.md
================
# Introduction

An open source agent orchestration framework built on top of the latest [OpenAI Assistants API](https://platform.openai.com/docs/assistants/overview/agents).

---

[![Subscribe on YouTube](https://img.shields.io/youtube/channel/subscribers/UCSv4qL8vmoSH7GaPjuqRiCQ
)](https://youtube.com/@vrsen/)
[![Follow on Twitter](https://img.shields.io/twitter/follow/__vrsen__.svg?style=social&label=Follow%20%40__vrsen__)](https://twitter.com/__vrsen__)
[![Join our Discord!](https://img.shields.io/discord/1200037936352202802?label=Discord)](https://discord.gg/cw2xBaWfFM)
[![Agents-as-a-Service](https://img.shields.io/website?label=Agents-as-a-Service&up_message=For%20Business&url=https%3A%2F%2Fvrsen.ai)](https://agents.vrsen.ai)


## What is Agency Swarm?

Agency Swarm started as a desire and effort of Arsenii Shatokhin (aka VRSEN) to fully automate his AI Agency with AI. By building this framework, we aim to simplify the agent creation process and enable anyone to create collaborative swarm of agents (Agencies), each with distinct roles and capabilities. By thinking about automation in terms of **real world entities**, such as agencies and specialized agent roles, we make it a lot more intuitive for both the agents and the users.


### Key Features

- **Customizable Agent Roles**: Define roles like CEO, virtual assistant, developer, etc., and customize their functionalities with [Assistants API](https://platform.openai.com/docs/assistants/overview).
- **Full Control Over Prompts**: Avoid conflicts and restrictions of pre-defined prompts, allowing full customization.
- **Tool Creation**: Tools within Agency Swarm are created using [Instructor](https://github.com/jxnl/instructor), which provides a convenient interface and automatic type validation.
- **Efficient Communication**: Agents communicate through a specially designed "send message" tool based on their own descriptions.
- **State Management**: Agency Swarm efficiently manages the state of your assistants on OpenAI, maintaining it in a special `settings.json` file.
- **Deployable in Production**: Agency Swarm is designed to be reliable and easily deployable in production environments.



## Agency Swarm vs Other Frameworks

Unlike other frameworks, Agency Swarm:

1. **Does not write prompts** for you.
2. Prevents hallucinations with automatic **type checking and error correction** with [instructor](https://github.com/jxnl/instructor/tree/main)
3. Allows you to easily define **communication flows**.

### **AutoGen** vs Agency Swarm

In AutoGen, by default, the next speaker is determined with an extra call to the model that emulates "role play" between the agents. [[1]](https://microsoft.github.https://microsoft.github.io/autogen/blog/2023/12/29/AgentDescriptionsio/autogen/blog/2023/12/29/AgentDescriptions) Not only this is very inefficient, but it also makes the system less controllable and less customizable, because you cannot control which agent can communicate with which other agent.

Recently, autogen has added support for [determining the next speaker based on certain hardcoded conditions](https://microsoft.github.io/autogen/docs/notebooks/agentchat_groupchat_customized/). While this does make your system more customizable, it completely undermines the main benefit of agentic systems - adaptability. In my opinion, **you should only determine the boundaries for your agents, not the conditions themselves, as you are unlikely to account for every single condition in the real world.** ([#113](https://github.com/VRSEN/agency-swarm/issues/113))

In Agency Swarm, on the other hand, the communication is handled through the special `SendMessage` tool. [[2]](https://github.com/VRSEN/agency-swarm/blob/81ff3ad5d854729bcfa755f19480d681efa8e72b/agency_swarm/agency/agency.py#L528) Your agents will determine who to communicate with by themselves based on their own descriptions. All you have to do is set the boundaries for their communication inside the agency chart.

### **CrewAI** vs Agency Swarm

CrewAI introduces a concept of "process" [[3]](https://docs.crewai.com/core-concepts/Processes/) into agent communication, which provides some control over the communication flow. However, the biggest problem with CrewAI is that it is built on top of Langchain, which was created long before any function-calling models were released. This means that there is no type checking or error correction, so any action that your agent takes (which is the most important part of the system) could cause the whole system to go down if the model hallucinates. The sole advantage of CrewAI is its compatibility with open-source models.

## Need help?

If you need quick help with Agency Swarm, feel free to ask in the [Discord server](https://discord.gg/cw2xBaWfFM).

If you need help creating custom agent swarms for your business, check out our [Agents-as-a-Service](https://agents.vrsen.ai/) subscription, or schedule a consultation with me at https://calendly.com/vrsen/ai-project-consultation

---

## License

This project is licensed under the terms of the MIT license.

================
File: quick_start.md
================
# Quick Start

When it comes to getting started with Agency Swarm, you have two options:

1. **Start from Scratch**: This is the best option if you want to get a feel for the framework and understand how it works. You can start by creating your own agents and tools, and then use them to create your own agencies.
2. **Use Genesis Swarm**: This is the best option if you want to get started quickly and don't want to spend time creating your own agents and tools. You can use the Genesis Agency to create your agent templates and tools, and then fine-tune them to your needs.
3. **Create agent templates with CLI**: This is the best option if you want to create a structured environment for each agent and tool. See [Advanced Agents](advanced-usage/agents.md) for more information.

### Installation

```python
pip install agency-swarm
```

## Start from Scratch

1. **Set Your OpenAI Key**:

    ```python
    from agency_swarm import set_openai_key
    set_openai_key("YOUR_API_KEY")
    ```

2. **Create Tools**: Define your custom tools with [Instructor](https://github.com/jxnl/instructor).
All tools must extend the `BaseTool` class and implement the `run` method.
    ```python
    from agency_swarm.tools import BaseTool
    from pydantic import Field

    class MyCustomTool(BaseTool):
        """
        A brief description of what the custom tool does.
        The docstring should clearly explain the tool's purpose and functionality.
        It will be used by the agent to determine when to use this tool.
        """

        # Define the fields with descriptions using Pydantic Field
        example_field: str = Field(
            ..., description="Description of the example field, explaining its purpose and usage for the Agent."
        )

        # Additional Pydantic fields as required
        # ...

        def run(self):
            """
            The implementation of the run method, where the tool's main functionality is executed.
            This method should utilize the fields defined above to perform the task.
            Doc string is not required for this method and will not be used by your agent.
            """

            # Your custom tool logic goes here
            do_something(self.example_field)

            # Return the result of the tool's operation as a string
            return "Result of MyCustomTool operation"
    ```


3. **Define Agent Roles**: Define your agent roles. For example, a CEO agent for managing tasks and a developer agent for executing tasks.

    ```python
    from agency_swarm import Agent

    ceo = Agent(name="CEO",
                description="Responsible for client communication, task planning and management.",
                instructions="You must converse with other agents to ensure complete task execution.", # can be a file like ./instructions.md
                tools=[])

    developer = Agent(name="Developer",
                      description="Responsible for executing tasks and providing feedback.",
                      instructions="You must execute the tasks provided by the CEO and provide feedback.", # can be a file like ./instructions.md
                      tools=[MyCustomTool])
    ```

4. **Create Agency**: Define your agency chart.

    Any agents that are listed in the same list (eg. `[[ceo, dev]]`) can communicate with each other. The top-level list (`[ceo]`) defines agents that can communicate with the user.

    ```python
    from agency_swarm import Agency

    agency = Agency([
        ceo,  # CEO will be the entry point for communication with the user
        [ceo, dev],  # CEO can initiate communication with Developer
    ], shared_instructions='You are a part of an ai development agency.\n\n') # shared instructions for all agents
    ```

    !!! note "Note on Communication Flows"
         In Agency Swarm, communication flows are directional, meaning they are established from left to right in the agency_chart definition. For instance, in the example above, the CEO can initiate a chat with the developer (dev), and the developer can respond in this chat. However, the developer cannot initiate a chat with the CEO.

   5. **Run Demo**:
   Run the demo to see your agents in action!

    Web interface:

    ```python
    agency.demo_gradio(height=900)
    ```

    Terminal version:

    ```python
    agency.run_demo()
    ```

    Backend version:

    ```python
    completion_output = agency.get_completion("Please create a new website for our client.", yield_messages=False)
    ```

## Use Genesis Agency

1. **Run the `genesis` command**: This will start the Genesis Agency in your terminal, that will create your agent templates for you.

    #### **Command Syntax:**

    ```bash
    agency-swarm genesis [--openai_key "YOUR_API_KEY"]
    ```

2. **Chat with Genesis CEO**: Provide as much context as possible to Genesis Agency. Make sure to include:
    - Your mission and goals.
    - The agents you want to involve and their communication flows.
    - Which tools or APIs each agent should have access to, if any.

3. **Fine Tune**: After Genesis has created your agents for you, you will see all the agent folders in the same directory where you ran the `genesis` command. You can then fine-tune the agents and tools as per your requirements. To do so, follow these steps:


      1. **Adjust Tools**: Modify the tools in the `tools` directories of each agent as per your requirements.
      2. **Adjust Instructions**: Modify the agents in the `agents` directories as per your requirements.
      3. **Run Agency**: Run the `agency.py` file, send your tasks and see how they perform.
      4. **Repeat**: Repeat the process until your agents are performing as expected.

    !!! note "Agent Development is an Iterative Process"
        Right now, all agent development is iterative. You will need to constantly monitor and adjust your system until it works as expected. In the future, this will become less of a problem, as larger and smarter models are released.

## Next Steps

- Learn how to create more Tools, Agents and Agencies
- Deploy in Production
